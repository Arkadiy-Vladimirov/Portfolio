\newpage
\section{Задание 7}

\begin{enumerate}
	\item Методом случайного поиска найти минимальное значение функции $f$ на 
    множестве $A = \{x_1, x_2 : x_1^2 + x_2^2 \leq 1\}$, т.е. $y = \min f(x)$, 
    где 
    \begin{equation*}
        f(x) = x_1^3\sin\left(\frac{1}{x_1}\right) + 
        10x_1 x_2^4\cos\left(\frac{1}{x_2}\right)
    \end{equation*}
    при $x_1 \neq 0$ и $x_2 \neq 0$, функция доопределяется по непрерывности 
    при $x_1 = 0$ или $x_2 = 0$.
    \item Методом имитации отжига найти минимальное значение функции Розенброка 
    $g$ в пространстве $\mathbb{R}^2$, где 
    \begin{center}
	    $g(x) = (x_1-1)^2+100(x_2-x_1^2)^2$
    \end{center}
    \item Оценить точность. Сравнить результаты со стандартными методами 
    оптимизации.
\end{enumerate}

\subsection{Случайный поиск}
    Случайный поиск релизуем следующим образом. Равномерно разбросаем на 
    единичном круге $A$ точки $(X_i,Y_i) \sim \mathrm{Uniform}(A)$, т.е.
    \begin{gather*}
        X_i = \sqrt{r} \cos(\phi),\\
        Y_i = \sqrt{r} \sin(\phi),
    \end{gather*}
    где $r \sim \mathrm{Uniform}[0,1], \phi \sim \mathrm{Uniform}[0,2\pi]$. Из 
    полученной выборки возьмем точку $(X_k,Y_k)$ доставляющюю минимум функции 
    $f$. Она и будет результатом работы алгоритма. Испытания см. таб. 
    \ref{randsearch}.

    \begin{table}[ht]
        \begin{tabular}{|cccc}
            Объем выборки & $argmin$           & $min$   \\[5pt]
            $n=10^3$      & ( 0.4135, -0.9091) & -1.2351 \\
            $n=10^4$      & (-0.3691, -0.9256) & -1.2557 \\
            $n=10^5$      & (-0.3472, -0.9372) & -1.2832 \\
            $n=10^6$      & (-0.3576, -0.9338) & -1.2883 \\
        \end{tabular}
        \caption{}
        \label{randsearch}
    \end{table}

\subsection{Отжиг}
        Алгоритм метода принимает некоторую точку $x_0$ как исходные данные. 
        Затем строится минимизирующая последовательность $\{x_i\}$. Точка $x_{i+1}$ 
        полчучается на основе текущей точки $x_i$, а именно: случайно 
        генерируется точка $x^*$, например из распределения 
        $\mathcal{N}(x_i,q_i\sigma^2 E)$, после чего точка $x^*$ с некоторой вероятностью
        становится точкой $x_{i+1}$
        \begin{equation*}
            \Prb{x^* \rightarrow x_{i+1} | x_i} = 
            \left\{\begin{aligned}
                1\quad, & F(x^*) \le F(x_i),\\
                \exp\left(-\frac{F(x^*)-F(x_i)}{q_i}\right),& F(x^*) \ge F(x_i).
            \end{aligned}\right.
        \end{equation*}
        В качестве $\{q_i\}$ берется обычно некоторая убывающая 
        последовательность, например геометрическая прогрессия со знаменателем 
        меньшим едиинцы.

        За $100$ шагов алгоритм с параметрами: $x_0 = (0,0), \sigma = 2, 
        q_0 = 1000, k = 0.93$ нашел $min = 0.0031$ в точке $x_{100} = 
        (1.0382, 1.0820)$.

\subsection{Оценка точности}
    Оценим точность случайного поиска. Пусть $x = (x_1, x_2)$~--- точка 
    минимума, $\hat{x} = (\hat{x}_1, \hat{x}_2)$ --- результат работы алгоритма.

    Вероятность того что хотя бы одна точка попадет в $\epsilon$-окрестность $x$ 
    составляет $1 - (1-2\epsilon^2)^n$. Таким образом
    \begin{equation*}
        \Prb{|x - \hat x| < \epsilon} = 1 - (1-2\epsilon^2)^n.
    \end{equation*}
    Ясно, что $|f(x) - f(\hat x)| < \|f'\||x - \hat{x}| < 
    \max_A \|f'\| |x - \hat{x}|$.
    Можно оценить $\max_A \|f'\|$ как
    \begin{equation*}
        \|f'\| = \sqrt{\left(\frac{\partial f}{\partial x_1}\right)^2 
        + \left(\frac{\partial f}{\partial x_2}\right)^2} \le  34.26.
    \end{equation*}

    Итого мы можем оценить ошибку $\psi_n = |f(x) - f(\hat x)|$ сверху величиной 
    $\epsilon$, с вероятностью $1 - (1-2(\frac{\epsilon}{34.26})^2)^n$.